{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(r\"D:\\datasets\\ArzEn-MultiGenre-version-1.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_whitespace_and_empty_strings(data):\n",
    "    # Handle whitespace and empty strings\n",
    "    data = data.apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    print(\"Whitespace & Empty Strings Handled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_missing_values(data):\n",
    "    # Identify missing values\n",
    "    missing_values = data.isnull().sum()\n",
    "    print(\"Missing Values:\")\n",
    "    print(missing_values)\n",
    "    \n",
    "    # Check percentage of missing values\n",
    "    missing_percentage = (missing_values / len(data)) * 100\n",
    "    \n",
    "    # Decide strategy for handling missing data\n",
    "    # Example: Delete rows with a high percentage of missing values\n",
    "    high_missing_percentage = missing_percentage[missing_percentage > 30]\n",
    "    if not high_missing_percentage.empty:\n",
    "        print(\"Deleting rows with high missing value percentage...\")\n",
    "        data.dropna(subset=high_missing_percentage.index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(data):\n",
    "    # Remove duplicates\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    print(\"Duplicates Removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_characters(data):\n",
    "    # Remove repeated characters\n",
    "    data = data.apply(lambda x: re.sub(r'(.)\\1+', r'\\1', x) if isinstance(x, str) else x)\n",
    "    print(\"Repeated Characters Removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_meaningless_words(data):\n",
    "    # Remove stop words using NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    data['english_Text'] = data['english_Text'].apply(lambda x: ' '.join([word for word in word_tokenize(str(x)) if word.lower() not in stop_words]))\n",
    "    print(\"Meaningless Words Removed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_multilingual_sentences(data):\n",
    "    # Handle sentences containing both languages\n",
    "    # Example: Split sentences into separate columns for each language\n",
    "    # Assuming the data is stored in a DataFrame with separate columns for English and Arabic\n",
    "    english_regex = r'[a-zA-Z]'\n",
    "    arabic_regex = r'[\\u0600-\\u06FF]'\n",
    "    \n",
    "    def split_multilingual(row):\n",
    "        if re.search(english_regex, str(row['english_Text'])) and re.search(arabic_regex, str(row['egyption_Text'])):\n",
    "            return pd.Series({'english_Text': re.sub(arabic_regex, '', str(row['english_Text'])), \n",
    "                              'egyption_Text': re.sub(english_regex, '', str(row['egyption_Text']))})\n",
    "        else:\n",
    "            return row\n",
    "    \n",
    "    data = data.apply(split_multilingual, axis=1)\n",
    "    print(\"Multilingual Sentences Handled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "egyption_Text     84\n",
      "english_Text     371\n",
      "category           0\n",
      "sub_category       0\n",
      "dtype: int64\n",
      "Duplicates Removed.\n",
      "Whitespace & Empty Strings Handled.\n",
      "Repeated Characters Removed.\n",
      "Meaningless Words Removed.\n",
      "Multilingual Sentences Handled.\n"
     ]
    }
   ],
   "source": [
    "# Task execution\n",
    "identify_missing_values(data)\n",
    "remove_duplicates(data)\n",
    "handle_whitespace_and_empty_strings(data)\n",
    "remove_repeated_characters(data)\n",
    "remove_meaningless_words(data)\n",
    "handle_multilingual_sentences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['egyption_Text', 'english_Text', 'category', 'sub_category'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       egyption_Text english_Text   category  sub_category\n",
      "count          24120        24204      24204         24204\n",
      "unique         16674        19847          3           307\n",
      "top             إيه؟          nan  Subtitles  the-stranger\n",
      "freq              31          371      15924          1953\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24204 entries, 0 to 26073\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   egyption_Text  24120 non-null  object\n",
      " 1   english_Text   24204 non-null  object\n",
      " 2   category       24204 non-null  object\n",
      " 3   sub_category   24204 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 945.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cleaned_data(Arzen)by MA2.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Output cleaned data to a new Excel file\n",
    "data.to_excel(\"cleaned_data(Arzen)by MA2.xlsx\", index=False)\n",
    "print(\"\\ncleaned_data(Arzen)by MA2.xlsx'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "file_path = r\"D:\\datasets\\cleaned_data(Arzen)by MA22.xlsx\"\n",
    "data = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values (Before):\n",
      "egyption_Text     18\n",
      "english_Text     111\n",
      "category           0\n",
      "sub_category       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display information about missing values before dropping\n",
    "print(\"Missing Values (Before):\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop rows containing NaN values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values (After):\n",
      "egyption_Text    0\n",
      "english_Text     0\n",
      "category         0\n",
      "sub_category     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display information about missing values after dropping\n",
    "print(\"\\nMissing Values (After):\")\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed data saved to: preprocessed_data(Smsm).xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save the preprocessed dataset to a new file\n",
    "preprocessed_file_path = \"preprocessed_data(Smsm).xlsx\"\n",
    "data.to_excel(preprocessed_file_path, index=False)\n",
    "print(\"\\nPreprocessed data saved to:\", preprocessed_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
